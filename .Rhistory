batchmeansc(5, 5000, .95)
batchmeansc(10, 1000, 0.95)
batchmeansc(10, 5000, .95)
batchmeansc(5, 1000, 0.99)
batchmeansc(5, 5000, .99)
batchmeansc(10, 1000, 0.99)
batchmeansc(10, 5000, .99)
batchmeansd = function(batch, batchlen, lam) {
array = rep(0, 5000)
currentState = 0
iters = batch*batchlen
for (i in 1:iters) {
currentState = max(currentState+rpois(1, lam)-1 , 0) - max(currentState+rpois(1, lam)-2 , 0)
array[i] = currentState
}
batchArr = rep(0, batch)
for (i in 1:batch) {
batchArr[i] = mean(array[(1+1000*(i-1)):(1000*i)])
}
alpha = mean(batchArr)
q = batch
std_dev = 0
for (i in 1:batch) {
std_dev = std_dev + (batchArr[i] -alpha)^2
}
var = sqrt(1/(q-1)*std_dev)
t = qt(.975, batch - 1)
return (c(alpha -t*var/sqrt(batch),alpha +t*var/sqrt(batch)))
}
batchmeansd(5, 1000, 0.5)
batchmeansd(5, 5000, .5)
batchmeansd(10, 1000, 0.5)
batchmeansd(10, 5000, .5)
batchmeansd(5, 1000, 0.9)
batchmeansd(5, 5000, .9)
batchmeansd(10, 1000, 0.9)
batchmeansd(10, 5000, .9)
batchmeansd(5, 1000, 0.95)
batchmeansd(5, 5000, .95)
batchmeansd(10, 1000, 0.95)
batchmeansd(10, 5000, .95)
batchmeansd(5, 1000, 0.99)
batchmeansd(5, 5000, .99)
batchmeansd(10, 1000, 0.99)
batchmeansd(10, 5000, .99)
batchmeanse = function(batch, batchlen, lam) {
array = rep(0, 5000)
currentState = 0
iters = batch*batchlen
for (i in 1:iters) {
z = rpois(1,lam)
currentState = max(currentState+z-1 , 0) - max(currentState+z-2 , 0)
array[i] = currentState
}
batchArr = rep(0, batch)
for (i in 1:batch) {
batchArr[i] = mean(array[(1+1000*(i-1)):(1000*i)])
}
alpha = mean(batchArr)
q = batch
std_dev = 0
for (i in 1:batch) {
std_dev = std_dev + (batchArr[i] -alpha)^2
}
var = sqrt(1/(q-1)*std_dev)
t = qt(.975, batch - 1)
return (c(alpha -t*var/sqrt(batch),alpha +t*var/sqrt(batch)))
}
batchmeanse(5, 1000, 0.5)
batchmeanse(5, 5000, .5)
batchmeanse(10, 1000, 0.5)
batchmeanse(10, 5000, .5)
batchmeanse(5, 1000, 0.9)
batchmeanse(5, 5000, .9)
batchmeanse(10, 1000, 0.9)
batchmeanse(10, 5000, .9)
batchmeanse(5, 1000, 0.95)
batchmeanse(5, 5000, .95)
batchmeanse(10, 1000, 0.95)
batchmeanse(10, 5000, .95)
batchmeanse(5, 1000, 0.99)
batchmeanse(5, 5000, .99)
batchmeanse(10, 1000, 0.99)
batchmeanse(10, 5000, .99)
# We can see that the confidence intervals are slightly tighter for the method of common random numbers; this is as expected!
batchmeansd(5, 1000, 0.5)
batchmeansd(5, 5000, .5)
batchmeansd(10, 1000, 0.5)
batchmeansd(10, 5000, .5)
batchmeansd(5, 1000, 0.9)
batchmeansd(5, 5000, .9)
batchmeansd(10, 1000, 0.9)
batchmeansd(10, 5000, .9)
batchmeansd(5, 1000, 0.95)
batchmeansd(5, 5000, .95)
batchmeansd(10, 1000, 0.95)
batchmeansd(10, 5000, .95)
batchmeansd(5, 1000, 0.99)
batchmeansd(5, 5000, .99)
batchmeansd(10, 1000, 0.99)
batchmeansd(10, 5000, .99)
batchmeansc(5, 1000, 0.5)
batchmeansc(5, 5000, .5)
batchmeansc(10, 1000, 0.5)
batchmeansc(10, 5000, .5)
setwd("~/Downloads")
data = read.csv("winequality-red.csv")
colnames(data)
sample.set = sample(1599, 1000)
train = data[sample.set,]
sample.test = sample(599, 200)
validation = data[sample.test, ]
test = data[-sample.test,]
library('e1071')
max_mse = 0
cv.cost = 0
for (i in seq(-8, -2, 0.1)) {
svm.fit = svm(train$quality~., data = train, kernel = 'linear', cost = 10^i, type = "C-classification")
pred = predict(svm.fit, validation)
test_mse = mean(pred == validation$quality)
if (test_mse > max_mse) {
max_mse = test_mse
cv.cost = i
}
}
max_mse
cv.cost
library('e1071')
svm.fit = svm(train$quality~., data = train, kernel = 'linear', cost = cv.cost, type = "C-classification", cross = 5)
pred = predict(svm.fit, validation)
mean(pred != validation$quality)
pred =predict(svm.fit, test)
mean(pred != test$quality)
for (i in 1:length(data)) {
print(colnames(data)[i])
print(min(data[i:i]))
print(max(data[i:i]))
}
vec = data.frame(rep(2, length(data)))
rownames(vec) = colnames(data)
vec = t(vec)
print(data.frame(predict(svm.fit, vec))[1])
typeof(pred)
pred[1]
pred[1:1]
pred[1]+1
data.matrix(pred)
data.matrix(pred)[1]
as.matrix(predict(svm.fit, vec))[1]
as.numeric(as.matrix(predict(svm.fit, vec))[1])
as.numeric(as.matrix(predict(svm.fit, vec))[1])+1
as.numeric(as.matrix(predict(svm.fit, vec))[1])-3
setwd("~/Downloads")
data = read.csv("winequality.csv")
colnames(data)
dim(data)
colnames(data)
sample.set = sample(6497, 4000)
train = data[sample.set,]
cur = data[-sample.set,]
sample.test = sample(6497-4000, 1000)
validation = cur[sample.test, ]
test = cur[-sample.test,]
dim(test)
dim(validation)
dim(train)
library('e1071')
max_mse = 0
cv.cost = 0
for (i in seq(-8, -2, 0.1)) {
svm.fit = svm(train$quality~., data = train, kernel = 'linear', cost = 10^i, type = "C-classification")
pred = predict(svm.fit, validation)
test_mse = mean(pred == validation$quality)
if (test_mse > max_mse) {
max_mse = test_mse
cv.cost = i
}
}
library('e1071')
max_mse = 0
cv.cost = 0
for (i in seq(-5, -2, 0.1)) {
svm.fit = svm(train$quality~., data = train, kernel = 'linear', cost = 10^i, type = "C-classification")
pred = predict(svm.fit, validation)
test_mse = mean(pred == validation$quality)
if (test_mse > max_mse) {
max_mse = test_mse
cv.cost = i
}
}
library('e1071')
max_mse = 0
cv.cost = 0
for (i in seq(-5, -4, 0.1)) {
svm.fit = svm(train$quality~., data = train, kernel = 'linear', cost = 10^i, type = "C-classification")
pred = predict(svm.fit, validation)
test_mse = mean(pred == validation$quality)
if (test_mse > max_mse) {
max_mse = test_mse
cv.cost = i
}
}
max_mse
cv.cost
setwd("~/Downloads")
data = read.csv("winequality-red.csv")
colnames(data)
sample.set = sample(1599, 1000)
train = data[sample.set,]
sample.test = sample(599, 200)
validation = data[sample.test, ]
test = data[-sample.test,]
library('e1071')
max_mse = 0
cv.cost = 0
for (i in seq(-8, -2, 0.1)) {
svm.fit = svm(train$quality~., data = train, kernel = 'linear', cost = 10^i, type = "C-classification")
pred = predict(svm.fit, validation)
test_mse = mean(pred == validation$quality)
if (test_mse > max_mse) {
max_mse = test_mse
cv.cost = 10^i
}
}
max_mse
cv.cost
library('e1071')
svm.fit = svm(train$quality~., data = train, kernel = 'linear', cost = cv.cost, type = "C-classification", cross = 5)
pred = predict(svm.fit, validation)
mean(pred != validation$quality)
pred =predict(svm.fit, test)
mean(pred != test$quality)
for (i in 1:length(data)) {
print(colnames(data)[i])
print(min(data[i:i]))
print(max(data[i:i]))
}
library('e1071')
max_mse = 0
cv.cost = 0
for (i in seq(-5, -4, 0.1)) {
svm.fit = svm(train$quality~., data = train, kernel = 'linear', cost = 10^i, type = "C-classification")
pred = predict(svm.fit, validation)
test_mse = mean(pred == validation$quality)
if (test_mse > max_mse) {
max_mse = test_mse
cv.cost = i
}
}
max_mse
cv.cost
library('e1071')
svm.fit = svm(train$quality~., data = train, kernel = 'linear', cost = 10^cv.cost, type = "C-classification", cross = 5)
pred = predict(svm.fit, validation)
mean(pred != validation$quality)
pred =predict(svm.fit, test)
mean(pred != test$quality)
for (i in 1:length(data)) {
print(colnames(data)[i])
print(min(data[i:i]))
print(max(data[i:i]))
}
setwd("~/Downloads")
data = read.csv("winequality.csv")
colnames(data)
sample.set = sample(6497, 4000)
train = data[sample.set,]
cur = data[-sample.set,]
sample.test = sample(6497-4000, 1000)
validation = cur[-sample.test, ]
test = cur[sample.test,]
library('e1071')
max_mse = 0
cv.cost = 0
for (i in seq(-5, -4, 0.1)) {
svm.fit = svm(train$quality~., data = train, kernel = 'linear', cost = 10^i, type = "C-classification")
pred = predict(svm.fit, validation)
test_mse = mean(pred == validation$quality)
if (test_mse > max_mse) {
max_mse = test_mse
cv.cost = i
}
}
max_mse
cv.cost
library('e1071')
svm.fit = svm(train$quality~., data = train, kernel = 'linear', cost = 10^cv.cost, type = "C-classification", cross = 5)
pred = predict(svm.fit, validation)
mean(pred != validation$quality)
pred =predict(svm.fit, test)
mean(pred != test$quality)
setwd("~/Downloads")
data = read.csv("winequality.csv")
colnames(data)
sample.set = sample(6497, 4000)
train = data[sample.set,]
cur = data[-sample.set,]
sample.test = sample(6497-4000, 1000)
validation = cur[-sample.test, ]
test = cur[sample.test,]
library('e1071')
max_mse = 0
cv.cost = 0
for (i in seq(-4, -2, 0.1)) {
svm.fit = svm(train$quality~., data = train, kernel = 'linear', cost = 10^i, type = "C-classification")
pred = predict(svm.fit, validation)
test_mse = mean(pred == validation$quality)
if (test_mse > max_mse) {
max_mse = test_mse
cv.cost = i
}
}
max_mse
cv.cost
library('e1071')
svm.fit = svm(train$quality~., data = train, kernel = 'linear', cost = 10^cv.cost, type = "C-classification", cross = 5)
pred = predict(svm.fit, validation)
mean(pred != validation$quality)
pred =predict(svm.fit, test)
mean(pred != test$quality)
setwd("~/Downloads")
data = read.csv("winequality.csv")
colnames(data)
sample.set = sample(6497, 3500)
train = data[sample.set,]
cur = data[-sample.set,]
sample.test = sample(6497-3500, 1500)
validation = cur[-sample.test, ]
test = cur[sample.test,]
library('e1071')
max_mse = 0
cv.cost = 0
for (i in seq(-3, -1, 0.1)) {
svm.fit = svm(train$quality~., data = train, kernel = 'linear', cost = 10^i, type = "C-classification")
pred = predict(svm.fit, validation)
test_mse = mean(pred == validation$quality)
if (test_mse > max_mse) {
max_mse = test_mse
cv.cost = i
}
}
max_mse
cv.cost
library('e1071')
svm.fit = svm(train$quality~., data = train, kernel = 'linear', cost = 10^cv.cost, type = "C-classification", cross = 5)
pred = predict(svm.fit, validation)
mean(pred != validation$quality)
pred =predict(svm.fit, test)
mean(pred != test$quality)
summary(svm.fit)
library('e1071')
max_mse = 0
cv.cost = 0
for (i in seq(-3, -1, 0.1)) {
svm.fit = svm(train$quality~., data = train, kernel = 'radial', cost = 10^i, type = "C-classification")
pred = predict(svm.fit, validation)
test_mse = mean(pred == validation$quality)
if (test_mse > max_mse) {
max_mse = test_mse
cv.cost = i
}
}
max_mse
cv.cost
library('e1071')
svm.fit = svm(train$quality~., data = train, kernel = 'radial', cost = 10^cv.cost, type = "C-classification", cross = 5)
pred = predict(svm.fit, validation)
mean(pred != validation$quality)
pred =predict(svm.fit, test)
mean(pred != test$quality)
# Misclassification error is around 28%
for (i in 1:length(data)) {
print(colnames(data)[i])
print(min(data[i:i]))
print(max(data[i:i]))
}
wine_score = function(vec, svm.fit) {
rownames(vec) = colnames(data)
vec = t(vec)
as.numeric(as.matrix(predict(svm.fit, vec))[1])-3
}
vec = data.frame(rep(2, length(data)))
rownames(vec) = colnames(data)
vec = t(vec)
as.numeric(as.matrix(predict(svm.fit, vec))[1])-3
library('e1071')
max_mse = 0
cv.cost = 0
for (i in seq(-2, 0.1, 0.1)) {
svm.fit = svm(train$quality~., data = train, kernel = 'radial', cost = 10^i, type = "C-classification")
pred = predict(svm.fit, validation)
test_mse = mean(pred == validation$quality)
if (test_mse > max_mse) {
max_mse = test_mse
cv.cost = i
}
}
max_mse
cv.cost
library('e1071')
svm.fit = svm(train$quality~., data = train, kernel = 'radial', cost = 10^cv.cost, type = "C-classification", cross = 5)
pred = predict(svm.fit, validation)
mean(pred != validation$quality)
pred =predict(svm.fit, test)
mean(pred != test$quality)
library('e1071')
max_mse = 0
cv.cost = 0
for (i in seq(-4, -2, 0.1)) {
svm.fit = svm(train$quality~., data = train, kernel = 'radial', cost = 10^i, type = "C-classification")
pred = predict(svm.fit, validation)
test_mse = mean(pred == validation$quality)
if (test_mse > max_mse) {
max_mse = test_mse
cv.cost = i
}
}
max_mse
cv.cost
library('e1071')
svm.fit = svm(train$quality~., data = train, kernel = 'radial', cost = 10^cv.cost, type = "C-classification", cross = 5)
pred = predict(svm.fit, validation)
mean(pred != validation$quality)
pred =predict(svm.fit, test)
mean(pred != test$quality)
# Misclassification error is around 28%
for (i in 1:length(data)) {
print(colnames(data)[i])
print(min(data[i:i]))
print(max(data[i:i]))
}
library('e1071')
max_mse = 0
cv.cost = 0
for (i in seq(-4, -2, 0.1)) {
svm.fit = svm(train$quality~., data = train, kernel = 'linear', cost = 10^i, type = "C-classification")
pred = predict(svm.fit, validation)
test_mse = mean(pred == validation$quality)
if (test_mse > max_mse) {
max_mse = test_mse
cv.cost = i
}
}
max_mse
cv.cost
library('e1071')
svm.fit = svm(train$quality~., data = train, kernel = 'linear', cost = 10^cv.cost, type = "C-classification", cross = 5)
pred = predict(svm.fit, validation)
mean(pred != validation$quality)
pred =predict(svm.fit, test)
mean(pred != test$quality)
# Misclassification error is around 28%
for (i in 1:length(data)) {
print(colnames(data)[i])
print(min(data[i:i]))
print(max(data[i:i]))
}
?tune
tune.out = tune(svm, train$quality~., data = train, kernel = 'linear', cost = 10^cv.cost, ranges = seq(-5, -2, .1))
tune.out = tune(svm, quality~. -quality, data = train, kernel = 'linear', cost = 10^cv.cost, ranges = seq(-5, -2, .1))
tune.out = tune(svm, quality~. -quality, data = train, kernel = 'linear', ranges = seq(-5, -2, .1))
library('e1071')
max_mse = 0
cv.cost = 0
for (i in seq(-4, -2, 0.1)) {
svm.fit = svm(train$quality~., data = train, kernel = 'linear', cost = 10^i, type = "C-classification")
pred = predict(svm.fit, validation)
test_mse = mean(pred == validation$quality)
if (test_mse > max_mse) {
max_mse = test_mse
cv.cost = i
}
}
max_mse
cv.cost
library('e1071')
svm.fit = svm(train$quality~., data = train, kernel = 'linear', cost = 10^cv.cost, type = "C-classification", cross = 5)
pred = predict(svm.fit, validation)
mean(pred != validation$quality)
pred =predict(svm.fit, test)
mean(pred != test$quality)
# Misclassification error is around 28%
pred
for (i in 1:length(data)) {
print(colnames(data)[i])
print(min(data[i:i]))
print(max(data[i:i]))
}
vec = data.frame(rep(2, length(data)))
rownames(vec) = colnames(data)
vec = t(vec)
as.numeric(as.matrix(predict(svm.fit, vec))[1])-3
vec
do.call(rep, input) %>%
wine_score = function(vec, svm.fit) {
rownames(vec) = colnames(data)
vec = t(vec)
as.numeric(as.matrix(predict(svm.fit, vec))[1])-3
}
summary(svm.fit)
save(svm.fit, file = "wine_support_vector_machine.rba")
summary(svm.fit)
do.call(rep, input) %>%
load("wine_support_vector_machine.rba")
vec = data.frame(input)
rownames(vec) = colnames(data)
vec = t(vec)
as.numeric(as.matrix(predict(svm.fit, vec))[1])-3
load("wine_support_vector_machine.rba")
setwd("~/Desktop/treehacks")
load("wine_support_vector_machine.rba")
summary(svm.fit)
